{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File C:\\Users\\DELL\\Downloads\\NTU_ML2017_Hung-yi-Lee_HW-master.zip\\NTU_ML2017_Hung-yi-Lee_HW-master\\HW2\\data\\train.csv does not exist: 'C:\\\\Users\\\\DELL\\\\Downloads\\\\NTU_ML2017_Hung-yi-Lee_HW-master.zip\\\\NTU_ML2017_Hung-yi-Lee_HW-master\\\\HW2\\\\data\\\\train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-28b3737fbe82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m     \u001b[0mtrainData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:\\\\Users\\\\DELL\\\\Downloads\\\\NTU_ML2017_Hung-yi-Lee_HW-master.zip\\\\NTU_ML2017_Hung-yi-Lee_HW-master\\\\HW2\\\\data\\\\train.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m     \u001b[0mtestData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:\\\\Users\\\\DELL\\\\Downloads\\\\NTU_ML2017_Hung-yi-Lee_HW-master.zip\\\\NTU_ML2017_Hung-yi-Lee_HW-master\\\\HW2\\\\data\\\\test.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File C:\\Users\\DELL\\Downloads\\NTU_ML2017_Hung-yi-Lee_HW-master.zip\\NTU_ML2017_Hung-yi-Lee_HW-master\\HW2\\data\\train.csv does not exist: 'C:\\\\Users\\\\DELL\\\\Downloads\\\\NTU_ML2017_Hung-yi-Lee_HW-master.zip\\\\NTU_ML2017_Hung-yi-Lee_HW-master\\\\HW2\\\\data\\\\train.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from numpy.linalg import inv\n",
    "from math import floor , log\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "output_dir = \"output/\"\n",
    "\n",
    "def dataProcess_X(rawData):\n",
    "    \n",
    "    if \"income\" in rawData.columns:\n",
    "        Data = rawData.drop([\"sex\",\"income\"], axis=1)\n",
    "    else:\n",
    "        Data = rawData.drop([\"sex\"],axis = 1)\n",
    "    listObjectColumn = [col for col in Data.columns if Data[col].dtypes == \"object\"] #read non-number column\n",
    "    listNonObjectColumn = [x for x in list(Data) if x not in listObjectColumn] #read number column\n",
    "    \n",
    "    Objectdata = Data[listObjectColumn]\n",
    "    NonObjectData = Data[listNonObjectColumn]\n",
    "    #insert set into nonobject data with male = 0 and female = 1\n",
    "    NonObjectData.insert(0, \"sex\", (rawData[\"sex\"] == \"Female\").astype(np.int))\n",
    "    #set every element in object rows as an attribute\n",
    "    ObjectData = pd.get_dummies(ObjectData)\n",
    "    \n",
    "    Data = pd.concat([NonObjectData, ObjectData],axis = 1)\n",
    "    Data_x = Data.astype(\"int64\")\n",
    "    # Data_y = (rawData[\"income\"] == \" <=50K\").astype(np.int)\n",
    "    \n",
    "    #normalize\n",
    "    Data_x = (Data_x - Data_x.mean()) / Data_x.std()\n",
    "    \n",
    "    \n",
    "    return Data_x\n",
    "    \n",
    "def dataProcess_Y(rawData):\n",
    "    df_y = rawData['income']\n",
    "    Data_y = pd.DataFrame((df_y =='>50K').astype(\"int64\"), columns=[\"income\"])\n",
    "    return Data_y\n",
    "\n",
    "def sigmoid(z):\n",
    "    \n",
    "    res = 1 / (1.0 + np.exp(-z))\n",
    "    return np.clip(res, 1e-8,(1-(1e-8)))\n",
    "\n",
    "def _shuffle(X, Y):\n",
    "    randomize = np.arange(X.shape[0])\n",
    "    np.random.shuffle(X[randomize],Y[randomize])\n",
    "    \n",
    "    return (X[randomize], Y[randomize])\n",
    "\n",
    "def split_valid_set(X, Y, percentage):\n",
    "    all_size = X.shape[0]\n",
    "    valid_size = int(floor(all_size * percentage))\n",
    "    \n",
    "    X , Y = _shuffle(X, Y)\n",
    "    X_valid , Y_valid = X[ :valid_size], Y[: valid_size]\n",
    "    X_train, Y_train = X[valid_size :], Y[valid_size :]\n",
    "    \n",
    "    return X_train, Y_train, X_valid, Y_valid\n",
    "\n",
    "def valid(X, Y, mu1, mu2, shared_sigma, N1, N2):\n",
    "    sigma_inv = inv(shared_sigma)\n",
    "    w = np.dot((mu1 - mu2), sigma_inv)\n",
    "    \n",
    "    X_t = X.T\n",
    "    b = (-0,5) * np.dot(np.dot(mu1.T, sigma_inv), mu1) + (0.5) * np.dot(np.dot(mu2.T, sigma_inv ),mu2) + np.log(float(N1)/N2)\n",
    "    a = np.dot(w, X_t) + b\n",
    "    y = sigmoid(a)\n",
    "    y_  = np.around(y)\n",
    "    result = (np.squeeze(Y) == y_)\n",
    "    print('Valid acc = %f' % (float(result.sum()) / result.shape[0]))\n",
    "    return\n",
    "\n",
    "def train(X_train, Y_train):\n",
    "    \n",
    "    #Gussian distribution parameters\n",
    "    train_data_size = X_train.shape[0]\n",
    "    \n",
    "    cnt1 = 0\n",
    "    cnt2 = 0\n",
    "    \n",
    "    mu1 = np.zeros((106,))\n",
    "    mu2 = np.zeros((106,))\n",
    "    for i in range(train_data_size):\n",
    "        if Y_train[i] == 1:\n",
    "            mu1 += X_train[i]\n",
    "            cnt1 += 1\n",
    "        else:\n",
    "            mu2 += X_train[i]\n",
    "            cnt2 += 1\n",
    "    mu1 /= cnt1\n",
    "    mu2 /= cnt2\n",
    "    \n",
    "    sigma1 = np.zeros((106,106))\n",
    "    sigma2 = np.zeros((106,106))\n",
    "    \n",
    "    for i in range(train_data_size):\n",
    "        if Y_train[i] == 1:\n",
    "            sigma1 += np.dot(np.transpose([X_train[i] - mu1]), [X_train[i] - mu1])\n",
    "        else:\n",
    "            sigma2 += np.dot(np.transpose([X_train[i] - mu2]), [X_train[i] - mu2])\n",
    "    \n",
    "    sigma1 /= cnt1\n",
    "    sigma2 /= cnt2\n",
    "    shared_sigma = (float(cnt1) / train_data_size) * sigma1 + (float(cnt2) / train_data_size) * sigma2\n",
    "    \n",
    "    N1 = cnt1\n",
    "    N2 = cnt2\n",
    "    \n",
    "    return mu1, mu2, shared_sigma, N1, N2\n",
    "\n",
    "if __name__ ==\"__main__\":\n",
    "    \n",
    "    trainData = pd.read_csv(\"train.csv\")\n",
    "    testData = pd.read_csv(\"test.csv\")\n",
    "    \n",
    "    ans = pd.read_csv(\"data/correct_answer.csv\")\n",
    "    \n",
    "#here is one more attribute in trainData\n",
    "    x_train = dataProcess_X(trainData).drop(['native_country_ Holand_Netherlands'],axis = 1).values\n",
    "    \n",
    "    x_test = dataProcess_X(testData).values\n",
    "    y__train = dataProcess_Y(trainData).values\n",
    "    y_ans = ans['label'].values\n",
    "    \n",
    "    valid_set_percetange = 0.1\n",
    "    X_train, Y_train, X_valid, y_valid = split_valid_set(x_train, y_train, valid_set_percentage)\n",
    "    mu1, mu2, shared_sigma, N1, N2 = train(X_train, Y_train)\n",
    "    valid(X_valid, Y_valid, mu1, mu2, shared_sigma, N1, N2)\n",
    "    \n",
    "    mu1, mu2, shared_sigma, N1, N2 = train(x_train, y_train)\n",
    "    \n",
    "    sigma_inv = inv(shared_sigma)\n",
    "    \n",
    "    w = np.dot((mu1 - mu2), sigma_inv)\n",
    "    \n",
    "    X_t = x_test.T\n",
    "    b = (-0.5) * np.dot(np.dot(mu1.T, sigma_inv), mu1) + (0.5) * np.dot(np.dot(mu2.T, sigma_inv), mu2) + np.log(float(N1) / N2)\n",
    "    \n",
    "    a = np.dot(w, X_t) + b\n",
    "    y = sigmoid(a)\n",
    "    y_ = np.around(y).astype(np.int)\n",
    "    \n",
    "    df = pd.DataFrame({\"id\": np.arange(1,16282), \"label\": y_})\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "    df.to_csv(os.path.join(output_dir + 'gd_output.csv'), sep = '\\t', index = False)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
